{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = GoogleAdsClient.load_from_dict(\n",
    "                name_to_api_key[client_credentials][\"credentials\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "Args:\n",
    "    client: An initialized Google Ads API client.\n",
    "    customer_id: The Google Ads customer ID.\n",
    "    language_name: String included in the language name to search for.\n",
    "\"\"\"\n",
    "# Get the GoogleAdsService client.\n",
    "googleads_service = client.get_service(\"MonthOfYearEnum\")\n",
    "\n",
    "# Create a query that retrieves the language constants where the name\n",
    "# includes a given string.\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "    language_constant.resource_name\n",
    "    FROM language_constant\n",
    "    WHERE language_constant.name LIKE '%{language_name}%'\"\"\"\n",
    "\n",
    "# Issue a search request and process the stream response to print the\n",
    "# requested field values for the carrier constant in each row.\n",
    "stream = googleads_service.search_stream(\n",
    "    customer_id=customer_id, query=query\n",
    ")\n",
    "batches = [batch.results for batch in stream]\n",
    "return batches[0][0].language_constant.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime(str(t), \"%m\").month +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = datetime.date(1900, t, 1).strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "December\n"
     ]
    }
   ],
   "source": [
    "print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pl.DataFrame({'month':[1,2,3,4,5,6,7,8,9,10], 'year':[2020,2022,2023,2024,2020,2022,2023,2024,2025,2022]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/p73_f5zd0dncgv67y8ctd0940000gn/T/ipykernel_4108/3114850471.py:1: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
      "  t.with_columns(pl.col(\"month\").apply(lambda x:datetime.date(1900, x, 1).strftime('%B')).alias(\"new\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>month</th><th>year</th><th>new</th></tr><tr><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>2020</td><td>&quot;January&quot;</td></tr><tr><td>2</td><td>2022</td><td>&quot;February&quot;</td></tr><tr><td>3</td><td>2023</td><td>&quot;March&quot;</td></tr><tr><td>4</td><td>2024</td><td>&quot;April&quot;</td></tr><tr><td>5</td><td>2020</td><td>&quot;May&quot;</td></tr><tr><td>6</td><td>2022</td><td>&quot;June&quot;</td></tr><tr><td>7</td><td>2023</td><td>&quot;July&quot;</td></tr><tr><td>8</td><td>2024</td><td>&quot;August&quot;</td></tr><tr><td>9</td><td>2025</td><td>&quot;September&quot;</td></tr><tr><td>10</td><td>2022</td><td>&quot;October&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌───────┬──────┬───────────┐\n",
       "│ month ┆ year ┆ new       │\n",
       "│ ---   ┆ ---  ┆ ---       │\n",
       "│ i64   ┆ i64  ┆ str       │\n",
       "╞═══════╪══════╪═══════════╡\n",
       "│ 1     ┆ 2020 ┆ January   │\n",
       "│ 2     ┆ 2022 ┆ February  │\n",
       "│ 3     ┆ 2023 ┆ March     │\n",
       "│ 4     ┆ 2024 ┆ April     │\n",
       "│ …     ┆ …    ┆ …         │\n",
       "│ 7     ┆ 2023 ┆ July      │\n",
       "│ 8     ┆ 2024 ┆ August    │\n",
       "│ 9     ┆ 2025 ┆ September │\n",
       "│ 10    ┆ 2022 ┆ October   │\n",
       "└───────┴──────┴───────────┘"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.with_columns(pl.col(\"month\").apply(lambda x:datetime.date(1900, x, 1).strftime('%B')).alias(\"new\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [\"AF\",\n",
    "\"AL\",\n",
    "\"DZ\",\n",
    "\"AO\",\n",
    "\"AR\",\n",
    "\"AM\",\n",
    "\"AU\",\n",
    "\"AT\",\n",
    "\"AZ\",\n",
    "\"BS\",\n",
    "\"BH\",\n",
    "\"BD\",\n",
    "\"BY\",\n",
    "\"BE\",\n",
    "\"BZ\",\n",
    "\"BO\",\n",
    "\"BA\",\n",
    "\"BW\",\n",
    "\"BR\",\n",
    "\"BN\",\n",
    "\"BG\",\n",
    "\"CV\",\n",
    "\"KH\",\n",
    "\"CM\",\n",
    "\"CA\",\n",
    "\"CL\",\n",
    "\"CO\",\n",
    "\"CG\",\n",
    "\"CR\",\n",
    "\"HR\",\n",
    "\"CY\",\n",
    "\"CZ\",\n",
    "\"DK\",\n",
    "\"DO\",\n",
    "\"EC\",\n",
    "\"EG\",\n",
    "\"SV\",\n",
    "\"EE\",\n",
    "\"ET\",\n",
    "\"FI\",\n",
    "\"FR\",\n",
    "\"GE\",\n",
    "\"DE\",\n",
    "\"GH\",\n",
    "\"GR\",\n",
    "\"GT\",\n",
    "\"GY\",\n",
    "\"HT\",\n",
    "\"HN\",\n",
    "\"HK\",\n",
    "\"HU\",\n",
    "\"IS\",\n",
    "\"IN\",\n",
    "\"ID\",\n",
    "\"IE\",\n",
    "\"IL\",\n",
    "\"IT\",\n",
    "\"JM\",\n",
    "\"JP\",\n",
    "\"JO\",\n",
    "\"KZ\",\n",
    "\"KW\",\n",
    "\"LV\",\n",
    "\"LB\",\n",
    "\"LY\",\n",
    "\"LT\",\n",
    "\"LU\",\n",
    "\"MG\",\n",
    "\"MY\",\n",
    "\"MT\",\n",
    "\"MU\",\n",
    "\"MX\",\n",
    "\"MD\",\n",
    "\"MN\",\n",
    "\"ME\",\n",
    "\"MA\",\n",
    "\"MZ\",\n",
    "\"NA\",\n",
    "\"NP\",\n",
    "\"NL\",\n",
    "\"NZ\",\n",
    "\"NI\",\n",
    "\"NG\",\n",
    "\"NO\",\n",
    "\"OM\",\n",
    "\"PK\",\n",
    "\"PY\",\n",
    "\"PE\",\n",
    "\"PH\",\n",
    "\"PL\",\n",
    "\"PT\",\n",
    "\"RO\",\n",
    "\"RU\",\n",
    "\"SA\",\n",
    "\"SN\",\n",
    "\"RS\",\n",
    "\"SG\",\n",
    "\"LK\",\n",
    "\"SK\",\n",
    "\"SI\",\n",
    "\"ZA\",\n",
    "\"KR\",\n",
    "\"ES\",\n",
    "\"SE\",\n",
    "\"TH\",\n",
    "\"TT\",\n",
    "\"TN\",\n",
    "\"TR\",\n",
    "\"UA\",\n",
    "\"AE\",\n",
    "\"UK\",\n",
    "\"US\",\n",
    "\"UY\",\n",
    "\"VE\",\n",
    "\"VN\",\n",
    "\"ZM\",\n",
    "\"ZW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x.lower() for x in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['af',\n",
       " 'al',\n",
       " 'dz',\n",
       " 'ao',\n",
       " 'ar',\n",
       " 'am',\n",
       " 'au',\n",
       " 'at',\n",
       " 'az',\n",
       " 'bs',\n",
       " 'bh',\n",
       " 'bd',\n",
       " 'by',\n",
       " 'be',\n",
       " 'bz',\n",
       " 'bo',\n",
       " 'ba',\n",
       " 'bw',\n",
       " 'br',\n",
       " 'bn',\n",
       " 'bg',\n",
       " 'cv',\n",
       " 'kh',\n",
       " 'cm',\n",
       " 'ca',\n",
       " 'cl',\n",
       " 'co',\n",
       " 'cg',\n",
       " 'cr',\n",
       " 'hr',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'dk',\n",
       " 'do',\n",
       " 'ec',\n",
       " 'eg',\n",
       " 'sv',\n",
       " 'ee',\n",
       " 'et',\n",
       " 'fi',\n",
       " 'fr',\n",
       " 'ge',\n",
       " 'de',\n",
       " 'gh',\n",
       " 'gr',\n",
       " 'gt',\n",
       " 'gy',\n",
       " 'ht',\n",
       " 'hn',\n",
       " 'hk',\n",
       " 'hu',\n",
       " 'is',\n",
       " 'in',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'il',\n",
       " 'it',\n",
       " 'jm',\n",
       " 'jp',\n",
       " 'jo',\n",
       " 'kz',\n",
       " 'kw',\n",
       " 'lv',\n",
       " 'lb',\n",
       " 'ly',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'mg',\n",
       " 'my',\n",
       " 'mt',\n",
       " 'mu',\n",
       " 'mx',\n",
       " 'md',\n",
       " 'mn',\n",
       " 'me',\n",
       " 'ma',\n",
       " 'mz',\n",
       " 'na',\n",
       " 'np',\n",
       " 'nl',\n",
       " 'nz',\n",
       " 'ni',\n",
       " 'ng',\n",
       " 'no',\n",
       " 'om',\n",
       " 'pk',\n",
       " 'py',\n",
       " 'pe',\n",
       " 'ph',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'ro',\n",
       " 'ru',\n",
       " 'sa',\n",
       " 'sn',\n",
       " 'rs',\n",
       " 'sg',\n",
       " 'lk',\n",
       " 'sk',\n",
       " 'si',\n",
       " 'za',\n",
       " 'kr',\n",
       " 'es',\n",
       " 'se',\n",
       " 'th',\n",
       " 'tt',\n",
       " 'tn',\n",
       " 'tr',\n",
       " 'ua',\n",
       " 'ae',\n",
       " 'uk',\n",
       " 'us',\n",
       " 'uy',\n",
       " 've',\n",
       " 'vn',\n",
       " 'zm',\n",
       " 'zw']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 20:02:53.595 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import polars as pl\n",
    "import io\n",
    "import pandas as pd\n",
    "import streamlit_authenticator as stauth\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import datetime \n",
    "import xlsxwriter\n",
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "\n",
    "\n",
    "\n",
    "API_KEY = 'e31f38c36540a234e23b614a7ffb4fc4'\n",
    "\n",
    "creds = {\n",
    "    'developer_token' : \"q2Om6GmAhWjE2z_p8Da_Fw\",\n",
    "    'client_id' : \"899223584116-m7n92thr3co9gr0otu7g64o85r6i46ko.apps.googleusercontent.com\",\n",
    "    'client_secret' : \"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\",\n",
    "    'refresh_token' : \"1//03aBH-xmgK1j6CgYIARAAGAMSNwF-L9IrHTMIAOSWIcjj147tjSBl5Z83teClPGIF2S-wcGCrCtO83BlRy5VaT4PoPA06_EVx5hQ\",\n",
    "    'use_proto_plus' : \"False\"} \n",
    "\n",
    "def search_for_language_constants(client, customer_id, language_name):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        language_constant.resource_name\n",
    "        FROM language_constant\n",
    "        WHERE language_constant.name LIKE '%{language_name}%'\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    batches = [batch.results for batch in stream]\n",
    "    return batches[0][0].language_constant.resource_name\n",
    "\n",
    "def language_full_list(client, customer_id):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        language_constant.name\n",
    "        FROM language_constant\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    t = []\n",
    "    for batch in stream:\n",
    "        for row in batch.results:\n",
    "            language_name = row.language_constant.name\n",
    "            t.append(language_name)\n",
    "    return t\n",
    "\n",
    "def map_locations_ids_to_resource_names(api_client, customer_id, location_name):\n",
    "    \"\"\"Converts a list of location IDs to resource names.\n",
    "\n",
    "    Args:\n",
    "        client: an initialized GoogleAdsClient instance.\n",
    "        location_ids: a list of location ID strings.\n",
    "\n",
    "    Returns:\n",
    "        a list of resource name strings using the given location IDs.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = api_client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        geo_target_constant.resource_name\n",
    "        FROM geo_target_constant\n",
    "        WHERE geo_target_constant.name LIKE '%{location_name}%'\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    batches = [batch.results for batch in stream]\n",
    "    return batches[0][0].geo_target_constant.resource_name\n",
    "\n",
    "def location_full_list(client, customer_id):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        geo_target_constant.name\n",
    "        FROM geo_target_constant\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    t = []\n",
    "    for batch in stream:\n",
    "        for row in batch.results:\n",
    "            location_name = row.geo_target_constant.name\n",
    "            t.append(location_name)\n",
    "    return t\n",
    "\n",
    "def generate_historical_metrics(api_client, customer_id,keywords,language,location,start_month,start_year,end_month,end_year):\n",
    "    overview = pl.DataFrame([])\n",
    "    final_overview = pl.DataFrame([])\n",
    "    monthly_results = pl.DataFrame([])\n",
    "    final_monthly_results = pl.DataFrame([])\n",
    "    \n",
    "    keyword = api_client.get_service(\"KeywordPlanIdeaService\")\n",
    "    request = api_client.get_type(\"GenerateKeywordHistoricalMetricsRequest\")\n",
    "    keyword_plan_network = api_client.get_type(\n",
    "        \"KeywordPlanNetworkEnum\"\n",
    "    ).KeywordPlanNetwork.GOOGLE_SEARCH_AND_PARTNERS\n",
    "    \n",
    "    request.customer_id = customer_id\n",
    "    request.language = search_for_language_constants(api_client, customer_id, language)\n",
    "    request.geo_target_constants.extend([map_locations_ids_to_resource_names(api_client, customer_id,location)])\n",
    "\n",
    "    request.keyword_plan_network = keyword_plan_network\n",
    "    request.keywords.extend(keywords)\n",
    "    request.historical_metrics_options.year_month_range.start.year = start_year\n",
    "    request.historical_metrics_options.year_month_range.start.month=start_month\n",
    "    request.historical_metrics_options.year_month_range.end.year = end_year\n",
    "    request.historical_metrics_options.year_month_range.end.month=end_month\n",
    "    keyword_historical_metrics_response = keyword.generate_keyword_historical_metrics(\n",
    "        request=request\n",
    "    )\n",
    "    for result in keyword_historical_metrics_response.results:\n",
    "        metric = result.keyword_metrics\n",
    "        overview = overview.with_columns(search_query=pl.lit(result.text), appro_monthly_search = pl.lit(metric.avg_monthly_searches),competition_level = pl.lit(metric.competition))\n",
    "        # These metrics include those for both the search query and any\n",
    "        # variants included in the response.\n",
    "        # If the metric is undefined, print (None) as a placeholder.\n",
    "        \n",
    "        final_overview = final_overview.vstack(overview)\n",
    "        \n",
    "        # Approximate number of searches on this query for the past twelve months.\n",
    "        for month in metric.monthly_search_volumes:\n",
    "            if month.month == 13:\n",
    "                monthly_results = monthly_results.with_columns(search_query=pl.lit(result.text),Appro_monthly=month.monthly_searches, month = 1,Year = month.year+1)\n",
    "                final_monthly_results = final_monthly_results.vstack(monthly_results)\n",
    "            else:   \n",
    "                monthly_results = monthly_results.with_columns(search_query=pl.lit(result.text),Appro_monthly=month.monthly_searches, month =month.month,Year = month.year) \n",
    "                final_monthly_results = final_monthly_results.vstack(monthly_results)\n",
    "                \n",
    "        final_monthly_results_final = final_monthly_results.with_columns(pl.col('month').apply(lambda x:datetime.date(1900, x, 1).strftime('%B')))\n",
    "        final_monthly_results_final = final_monthly_results_final.with_columns(pl.concat_str([pl.col(\"month\"),pl.col(\"Year\")],separator=\" \").alias('Date'))\n",
    "        \n",
    "    return final_overview,final_monthly_results_final.pivot(values =\"Appro_monthly\", index = \"search_query\", columns = \"Date\"),final_monthly_results_final\n",
    "    \n",
    "# Function to download the DataFrame as an Excel file\n",
    "\n",
    "\n",
    "def to_excel(dfs, sheet_names):\n",
    "    \"\"\"\n",
    "    Convert multiple dataframes to one Excel file with multiple sheets\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    with xlsxwriter.Workbook(output) as writer:\n",
    "        for df, sheet_name in zip(dfs, sheet_names):\n",
    "            df.write_excel(writer, worksheet=sheet_name,has_header=True,autofit=True)\n",
    "    output.seek(0)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Streamlit UI\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    name_to_api_key = {\n",
    "        \"Leclerc\": {\n",
    "            \"client_id\": \"3117864871\",\n",
    "            \"credentials\": creds\n",
    "        },\n",
    "        \"BLW\": {\n",
    "            \"client_id\": \"3117864871\",\n",
    "            \"credentials\": creds         \n",
    "        }\n",
    "    }\n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .logo {\n",
    "        max-width: 10%;\n",
    "        position: absolute;\n",
    "        top: 15px;\n",
    "        left: 15px;\n",
    "        z-index: 999;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Display the logo\n",
    "    st.image(\"./logo.png\", use_column_width=True)  # Using OpenAI's favicon as an example logo\n",
    "    \n",
    "    # Add a spacer after the logo\n",
    "    st.write(\"\\n\\n\\n\")\n",
    "    st.title(\"Google Ads\")\n",
    "    st.write(\"Enter a keyword and select a country to fetch SEO data.\")\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Upload an Excel file containing keywords\", type=[\"xlsx\"])\n",
    "        \n",
    "    # Allow user to manually enter keywords\n",
    "    keywords_input = st.text_area(\"Or enter keywords manually (seperated by a , )\")\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    client_credentials = st.selectbox(\"Select a Google Ads account:\", [\"Leclerc\", \"BLW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = GoogleAdsClient.load_from_dict(\n",
    "                name_to_api_key[client_credentials][\"credentials\"]\n",
    "            )\n",
    "client_ = name_to_api_key[client_credentials][\"client_id\"]\n",
    "t = language_full_list(api_client,client_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_language = language_full_list(api_client,client_)\n",
    "list_location=location_full_list(api_client,client_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m list_language\u001b[39m.\u001b[39;49mto_csv()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "list_language.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_location = pl.DataFrame({\"location\":list_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_language = pl.DataFrame({\"language\":list_language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path: pathlib.Path =\"list_location.csv\"\n",
    "list_location.write_csv(path, separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path: pathlib.Path =\"list_language.csv\"\n",
    "list_language.write_csv(path, separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pl.read_csv(\"list_location.csv\",truncate_ragged_lines=True, skip_rows=1).drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = pl.read_csv(\"list_language.csv\",truncate_ragged_lines=True, skip_rows=1).drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Antarctica',)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location.rows()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import polars as pl\n",
    "import io\n",
    "import pandas as pd\n",
    "import streamlit_authenticator as stauth\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import xlsxwriter\n",
    "\n",
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "\n",
    "\n",
    "\n",
    "API_KEY = 'e31f38c36540a234e23b614a7ffb4fc4'\n",
    "\n",
    "creds = {\n",
    "    'developer_token' : \"q2Om6GmAhWjE2z_p8Da_Fw\",\n",
    "    'client_id' : \"899223584116-m7n92thr3co9gr0otu7g64o85r6i46ko.apps.googleusercontent.com\",\n",
    "    'client_secret' : \"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\",\n",
    "    'refresh_token' : \"1//03aBH-xmgK1j6CgYIARAAGAMSNwF-L9IrHTMIAOSWIcjj147tjSBl5Z83teClPGIF2S-wcGCrCtO83BlRy5VaT4PoPA06_EVx5hQ\",\n",
    "    'use_proto_plus' : \"False\"} \n",
    "\n",
    "\n",
    "def brand_ranking (keywords,DB,your_brand_domain): \n",
    "    \n",
    "    dfs_r = pl.DataFrame([])  # List to store dataframes for each keyword\n",
    "    your_brand_position = None\n",
    "    competitors = pl.DataFrame([])\n",
    "    t = pl.DataFrame([])\n",
    "    b = pl.DataFrame([])\n",
    "    rank = pl.DataFrame([])\n",
    "    for keyword in keywords:\n",
    "        url = f\"https://api.semrush.com/?type=phrase_organic&key={API_KEY}&phrase={keyword}&export_columns=Kd,Dn,Po,&database={DB}\"\n",
    "        response = requests.get(url)\n",
    "        # Make sure the request was successful before processing\n",
    "        if response.status_code == 200:\n",
    "            df = pl.read_csv(io.StringIO(response.text), separator=';', eol_char='\\n').with_columns(Key=pl.lit(keyword))\n",
    "            dfs_r = dfs_r.vstack(df)\n",
    "            \n",
    "            for i in range(len(df)):\n",
    "                domain = df['Domain'][i]\n",
    "                position = df['Position'][i]\n",
    "                Keys = df['Key'][i]\n",
    "                for j in range (len(your_brand_domain)):\n",
    "                    if (domain in your_brand_domain[j]) or (your_brand_domain[j] in domain):\n",
    "                        your_brand_position = position\n",
    "    \n",
    "                        b = b.with_columns(keyword = pl.lit(Keys),brand_domain = pl.lit(your_brand_domain[j]),brand_ranking= pl.lit(your_brand_position))\n",
    "                        rank = rank.vstack(b)\n",
    "    \n",
    "                    else:\n",
    "                        t = t.with_columns(keyword = pl.lit(Keys),brand_domain = pl.lit(domain), brand_ranking= pl.lit(position))\n",
    "                        competitors = competitors.vstack(t)            \n",
    "        else:\n",
    "            print(f\"Failed to fetch data for keyword: {keyword}. Status Code: {response.status_code}\")\n",
    "                \n",
    "    return rank.pivot(values=\"brand_ranking\",index=\"brand_domain\",columns=\"keyword\"), competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings, competition = brand_ranking([\"robe\",\"jupe\"],\"fr\",[\"laredoute\",\"zara\",\"asos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [\"laredoute\",\"zara\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [1, 2, 3, 1],\n",
    "        \"bar\": [\"a\", \"a\", \"a\", \"a\"],\n",
    "        \"ham\": [\"b\", \"b\", \"b\", \"b\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>foo</th><th>bar</th><th>ham</th></tr></thead><tbody><tr><td>1</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr><tr><td>2</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr><tr><td>3</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr><tr><td>1</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────┬─────┬─────┐\n",
       "│ foo ┆ bar ┆ ham │\n",
       "╞═════╪═════╪═════╡\n",
       "│ 1   ┆ a   ┆ b   │\n",
       "│ 2   ┆ a   ┆ b   │\n",
       "│ 3   ┆ a   ┆ b   │\n",
       "│ 1   ┆ a   ┆ b   │\n",
       "└─────┴─────┴─────┘"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>foo</th><th>bar</th><th>ham</th></tr></thead><tbody><tr><td>1</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr><tr><td>2</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr><tr><td>3</td><td>&quot;a&quot;</td><td>&quot;b&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌─────┬─────┬─────┐\n",
       "│ foo ┆ bar ┆ ham │\n",
       "╞═════╪═════╪═════╡\n",
       "│ 1   ┆ a   ┆ b   │\n",
       "│ 2   ┆ a   ┆ b   │\n",
       "│ 3   ┆ a   ┆ b   │\n",
       "└─────┴─────┴─────┘"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.unique(subset=[\"foo\",\"bar\", \"ham\"], maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (200, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>keyword</th><th>brand_domain</th><th>brand_ranking</th></tr></thead><tbody><tr><td>&quot;robe&quot;</td><td>&quot;zalando.fr&quot;</td><td>1</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;galerieslafaye…</td><td>2</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;morgandetoi.fr…</td><td>3</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;blancheporte.f…</td><td>4</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;pimkie.fr&quot;</td><td>5</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;asos.com&quot;</td><td>6</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;etam.com&quot;</td><td>7</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;vibs.com&quot;</td><td>8</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;hm.com&quot;</td><td>9</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;zara.com&quot;</td><td>10</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;sarenza.com&quot;</td><td>11</td></tr><tr><td>&quot;robe&quot;</td><td>&quot;mango.com&quot;</td><td>12</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;bhv.fr&quot;</td><td>89</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;intersport.fr&quot;</td><td>90</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;spartoo.com&quot;</td><td>91</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;e-carnaby.com&quot;</td><td>92</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;deeluxe.fr&quot;</td><td>93</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;superdry.fr&quot;</td><td>94</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;modz.fr&quot;</td><td>95</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;veromoda.com&quot;</td><td>96</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;roxy.fr&quot;</td><td>97</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;daxon.fr&quot;</td><td>98</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;liujo.com&quot;</td><td>99</td></tr><tr><td>&quot;jupe&quot;</td><td>&quot;billabong.fr&quot;</td><td>100</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (200, 3)\n",
       "┌─────────┬───────────────────────┬───────────────┐\n",
       "│ keyword ┆ brand_domain          ┆ brand_ranking │\n",
       "╞═════════╪═══════════════════════╪═══════════════╡\n",
       "│ robe    ┆ zalando.fr            ┆ 1             │\n",
       "│ robe    ┆ galerieslafayette.com ┆ 2             │\n",
       "│ robe    ┆ morgandetoi.fr        ┆ 3             │\n",
       "│ robe    ┆ blancheporte.fr       ┆ 4             │\n",
       "│ …       ┆ …                     ┆ …             │\n",
       "│ jupe    ┆ roxy.fr               ┆ 97            │\n",
       "│ jupe    ┆ daxon.fr              ┆ 98            │\n",
       "│ jupe    ┆ liujo.com             ┆ 99            │\n",
       "│ jupe    ┆ billabong.fr          ┆ 100           │\n",
       "└─────────┴───────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streamlit UI\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .logo {\n",
    "        max-width: 10%;\n",
    "        position: absolute;\n",
    "        top: 15px;\n",
    "        left: 15px;\n",
    "        z-index: 999;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Display the logo\n",
    "    st.image(\"./logo.png\", use_column_width=True)  # Using OpenAI's favicon as an example logo\n",
    "\n",
    "    # Add a spacer after the logo\n",
    "    st.write(\"\\n\\n\\n\")\n",
    "    st.title(\"SemRush\")\n",
    "    st.write(\"Enter a keyword and select a country to fetch SEO data.\")\n",
    "\n",
    "    # Check if user input is already in session state\n",
    "    if 'user_input' not in st.session_state or st.session_state.user_input is None:\n",
    "        uploaded_file = st.file_uploader('Upload a file', type=['xlsx'])\n",
    "        if uploaded_file is not None:\n",
    "            st.session_state.user_input = uploaded_file\n",
    "    else:\n",
    "        uploaded_file = st.session_state.user_input\n",
    "\n",
    "    keywords_input = st.text_area('Or enter keywords (comma-separated)', '')\n",
    "    \n",
    "    if keywords_input:\n",
    "        st.session_state.user_input = keywords_input\n",
    "        keywords = keywords_input.split(',')\n",
    "        your_brand_domain_input = your_brand_domain.split(',')\n",
    "        # Fetch and display SEO data\n",
    "        rankings, competition = brand_ranking(keywords,DB.lower(),your_brand_domain_input)\n",
    "        # Initialize the GoogleAdsClient with the credentials and developer token\n",
    "        #api_client = GoogleAdsClient.load_from_storage(\"cred.yaml\")\n",
    "        \n",
    "        st.write(\"SemRush Keyword's ranking \")\n",
    "        filtered_rankings = dataframe_explorer(rankings.to_pandas(), case=False)\n",
    "        st.dataframe(filtered_rankings,hide_index =True,use_container_width=True)\n",
    "        filtered_competition = dataframe_explorer(competition.to_pandas(), case=False)\n",
    "        st.dataframe(filtered_competition,hide_index =True,use_container_width=True)\n",
    "        \n",
    "        \n",
    "    st.write(\"\\n\\n\\n\")\n",
    "    excel_file = to_excel([rankings], [\"SemRush_Keyword\", \"SemRush_Ranking\"])\n",
    "    st.download_button(\n",
    "    label=\"Download Excel file\",\n",
    "    data=excel_file,\n",
    "    file_name=\"dataframes.xlsx\",\n",
    "    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (595,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th></tr></thead><tbody><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>&hellip;</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr><tr><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (595,)\n",
       "Series: '' [bool]\n",
       "[\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\t…\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition.is_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def set_day_to_15(date_str, date_format=\"%Y-%m-%d\"):\n",
    "    \"\"\"\n",
    "    Set the day in the given date string to 15.\n",
    "\n",
    "    Parameters:\n",
    "    - date_str (str): The input date string.\n",
    "    - date_format (str): The format of the input date string. Default is \"%Y-%m-%d\" (e.g., \"2023-10-06\").\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified date string with the day set to 15.\n",
    "    \"\"\"\n",
    "    date_obj = datetime.strptime(date_str, date_format)\n",
    "    modified_date_obj = date_obj.replace(day=15)\n",
    "    return modified_date_obj.strftime(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-15\n"
     ]
    }
   ],
   "source": [
    "date = \"2023-10-06\"\n",
    "new_date = set_day_to_15(date)\n",
    "print(new_date)  # Output: \"2023-10-15\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import polars as pl\n",
    "import io\n",
    "import pandas as pd\n",
    "import streamlit_authenticator as stauth\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import datetime \n",
    "import xlsxwriter\n",
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "\n",
    "\n",
    "\n",
    "API_KEY = 'e31f38c36540a234e23b614a7ffb4fc4'\n",
    "\n",
    "creds = {\n",
    "    'developer_token' : \"q2Om6GmAhWjE2z_p8Da_Fw\",\n",
    "    'client_id' : \"899223584116-m7n92thr3co9gr0otu7g64o85r6i46ko.apps.googleusercontent.com\",\n",
    "    'client_secret' : \"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\",\n",
    "    'refresh_token' : \"1//03aBH-xmgK1j6CgYIARAAGAMSNwF-L9IrHTMIAOSWIcjj147tjSBl5Z83teClPGIF2S-wcGCrCtO83BlRy5VaT4PoPA06_EVx5hQ\",\n",
    "    'use_proto_plus' : \"False\"} \n",
    "\n",
    "def search_for_language_constants(client, customer_id, language_name):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        language_constant.resource_name\n",
    "        FROM language_constant\n",
    "        WHERE language_constant.name LIKE '%{language_name}%'\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    batches = [batch.results for batch in stream]\n",
    "    return batches[0][0].language_constant.resource_name\n",
    "\n",
    "def language_full_list(client, customer_id):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        language_constant.name\n",
    "        FROM language_constant\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    t = []\n",
    "    for batch in stream:\n",
    "        for row in batch.results:\n",
    "            language_name = row.language_constant.name\n",
    "            t.append(language_name)\n",
    "    return t\n",
    "\n",
    "def map_locations_ids_to_resource_names(api_client, customer_id, location_name):\n",
    "    \"\"\"Converts a list of location IDs to resource names.\n",
    "\n",
    "    Args:\n",
    "        client: an initialized GoogleAdsClient instance.\n",
    "        location_ids: a list of location ID strings.\n",
    "\n",
    "    Returns:\n",
    "        a list of resource name strings using the given location IDs.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = api_client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        geo_target_constant.resource_name\n",
    "        FROM geo_target_constant\n",
    "        WHERE geo_target_constant.name LIKE '%{location_name}%'\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    batches = [batch.results for batch in stream]\n",
    "    return batches[0][0].geo_target_constant.resource_name\n",
    "\n",
    "def location_full_list(client, customer_id):\n",
    "    \"\"\"Searches for language constants where the name includes a given string.\n",
    "\n",
    "    Args:\n",
    "        client: An initialized Google Ads API client.\n",
    "        customer_id: The Google Ads customer ID.\n",
    "        language_name: String included in the language name to search for.\n",
    "    \"\"\"\n",
    "    # Get the GoogleAdsService client.\n",
    "    googleads_service = client.get_service(\"GoogleAdsService\")\n",
    "\n",
    "    # Create a query that retrieves the language constants where the name\n",
    "    # includes a given string.\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "        geo_target_constant.name\n",
    "        FROM geo_target_constant\"\"\"\n",
    "\n",
    "    # Issue a search request and process the stream response to print the\n",
    "    # requested field values for the carrier constant in each row.\n",
    "    stream = googleads_service.search_stream(\n",
    "        customer_id=customer_id, query=query\n",
    "    )\n",
    "    t = []\n",
    "    for batch in stream:\n",
    "        for row in batch.results:\n",
    "            location_name = row.geo_target_constant.name\n",
    "            t.append(location_name)\n",
    "    return t\n",
    "\n",
    "def generate_historical_metrics(api_client, customer_id,keywords,language,location,start_month,start_year,end_month,end_year):\n",
    "    overview = pl.DataFrame([])\n",
    "    final_overview = pl.DataFrame([])\n",
    "    monthly_results = pl.DataFrame([])\n",
    "    final_monthly_results = pl.DataFrame([])\n",
    "    \n",
    "    keyword = api_client.get_service(\"KeywordPlanIdeaService\")\n",
    "    request = api_client.get_type(\"GenerateKeywordHistoricalMetricsRequest\")\n",
    "    keyword_plan_network = api_client.get_type(\n",
    "        \"KeywordPlanNetworkEnum\"\n",
    "    ).KeywordPlanNetwork.GOOGLE_SEARCH_AND_PARTNERS\n",
    "    \n",
    "    request.customer_id = customer_id\n",
    "    request.language = search_for_language_constants(api_client, customer_id, language)\n",
    "    request.geo_target_constants.extend([map_locations_ids_to_resource_names(api_client, customer_id,location)])\n",
    "\n",
    "    request.keyword_plan_network = keyword_plan_network\n",
    "    request.keywords.extend(keywords)\n",
    "    request.historical_metrics_options.year_month_range.start.year = start_year\n",
    "    request.historical_metrics_options.year_month_range.start.month=start_month\n",
    "    request.historical_metrics_options.year_month_range.end.year = end_year\n",
    "    request.historical_metrics_options.year_month_range.end.month=end_month\n",
    "    keyword_historical_metrics_response = keyword.generate_keyword_historical_metrics(\n",
    "        request=request\n",
    "    )\n",
    "    for result in keyword_historical_metrics_response.results:\n",
    "        metric = result.keyword_metrics\n",
    "        overview = overview.with_columns(search_query=pl.lit(result.text), appro_monthly_search = pl.lit(metric.avg_monthly_searches),competition_level = pl.lit(metric.competition))\n",
    "        # These metrics include those for both the search query and any\n",
    "        # variants included in the response.\n",
    "        # If the metric is undefined, print (None) as a placeholder.\n",
    "        \n",
    "        final_overview = final_overview.vstack(overview)\n",
    "        \n",
    "        # Approximate number of searches on this query for the past twelve months.\n",
    "        for month in metric.monthly_search_volumes:\n",
    "            if month.month == 13:\n",
    "                monthly_results = monthly_results.with_columns(search_query=pl.lit(result.text),Appro_monthly=month.monthly_searches, month = 1,Year = month.year+1)\n",
    "                final_monthly_results = final_monthly_results.vstack(monthly_results)\n",
    "            else:   \n",
    "                monthly_results = monthly_results.with_columns(search_query=pl.lit(result.text),Appro_monthly=month.monthly_searches, month =month.month,Year = month.year) \n",
    "                final_monthly_results = final_monthly_results.vstack(monthly_results)\n",
    "                \n",
    "        final_monthly_results_final = final_monthly_results.with_columns(pl.col('month').apply(lambda x:datetime.date(1900, x, 1).strftime('%B')))\n",
    "        final_monthly_results_final = final_monthly_results_final.with_columns(pl.concat_str([pl.col(\"month\"),pl.col(\"Year\")],separator=\" \").alias('Date'))\n",
    "        \n",
    "    return final_overview,final_monthly_results_final.pivot(values =\"Appro_monthly\", index = \"search_query\", columns = \"Date\"),final_monthly_results_final\n",
    "    \n",
    "# Function to download the DataFrame as an Excel file\n",
    "\n",
    "\n",
    "def to_excel(dfs, sheet_names):\n",
    "    \"\"\"\n",
    "    Convert multiple dataframes to one Excel file with multiple sheets\n",
    "    \"\"\"\n",
    "    output = io.BytesIO()\n",
    "    with xlsxwriter.Workbook(output) as writer:\n",
    "        for df, sheet_name in zip(dfs, sheet_names):\n",
    "            df.write_excel(writer, worksheet=sheet_name,has_header=True,autofit=True)\n",
    "    output.seek(0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'France'\n",
    "DB = 'fr'\n",
    "start_month = 'August'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview, monthly_results, graph = generate_historical_metrics(api_client,client_,keywords,lang,DB,start_month,start_year,end_month,end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at /Users/runner/work/polars/polars/crates/polars-time/src/chunkedarray/utf8/mod.rs:147:35:\n",
      "byte index 5 is out of bounds of `020`\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "byte index 5 is out of bounds of `020`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mfrom_repr(\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m┌─────┬──────────────────┐\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m│ id  ┆ event_date       │\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m└─────┴──────────────────┘\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df\u001b[39m.\u001b[39;49mwith_columns(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m    pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mevent_date\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mstrptime(pl\u001b[39m.\u001b[39;49mDate,\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mB \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m\"\u001b[39;49m,strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, exact \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X51sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/dataframe/frame.py:7861\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   7710\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwith_columns\u001b[39m(\n\u001b[1;32m   7711\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   7712\u001b[0m     \u001b[39m*\u001b[39mexprs: IntoExpr \u001b[39m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   7713\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   7714\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   7715\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7716\u001b[0m \u001b[39m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   7717\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7856\u001b[0m \n\u001b[1;32m   7857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   7858\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m   7859\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy()\n\u001b[1;32m   7860\u001b[0m         \u001b[39m.\u001b[39;49mwith_columns(\u001b[39m*\u001b[39;49mexprs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnamed_exprs)\n\u001b[0;32m-> 7861\u001b[0m         \u001b[39m.\u001b[39;49mcollect(no_optimization\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   7862\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/utils/deprecation.py:95\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     92\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     93\u001b[0m         old_name, new_name, kwargs, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, version\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/lazyframe/frame.py:1695\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, streaming)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     comm_subplan_elim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1686\u001b[0m     type_coercion,\n\u001b[1;32m   1687\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     streaming,\n\u001b[1;32m   1694\u001b[0m )\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39mcollect())\n",
      "\u001b[0;31mPanicException\u001b[0m: byte index 5 is out of bounds of `020`"
     ]
    }
   ],
   "source": [
    "df = pl.from_repr(\"\"\"\n",
    "┌─────┬──────────────────┐\n",
    "│ id  ┆ event_date       │\n",
    "│ --- ┆ ---              │\n",
    "│ i64 ┆ str              │\n",
    "╞═════╪══════════════════╡\n",
    "│ 1   ┆ July 2020     │\n",
    "│ 2   ┆ December 2020 │\n",
    "└─────┴──────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "df.with_columns(\n",
    "   pl.col(\"event_date\").str.strptime(pl.Date,\"%B %Y\",strict=False, exact = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.DataFrame ({\n",
    "    'month_year': ['01 09 2013','01 09 2013','01 09 2013'],\n",
    "    'value': [100, 200, 150]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.with_columns(\n",
    "               pl.col(\"month_year\").str.to_date(\"%d %m %Y\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>month_year</th><th>value</th></tr></thead><tbody><tr><td>2013-09-01</td><td>100</td></tr><tr><td>2013-09-01</td><td>200</td></tr><tr><td>2013-09-01</td><td>150</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────┬───────┐\n",
       "│ month_year ┆ value │\n",
       "╞════════════╪═══════╡\n",
       "│ 2013-09-01 ┆ 100   │\n",
       "│ 2013-09-01 ┆ 200   │\n",
       "│ 2013-09-01 ┆ 150   │\n",
       "└────────────┴───────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2018-01-01\n",
       "1      2018-01-08\n",
       "2      2018-01-15\n",
       "3      2018-01-22\n",
       "4      2018-01-29\n",
       "          ...    \n",
       "100    2019-12-02\n",
       "101    2019-12-09\n",
       "102    2019-12-16\n",
       "103    2019-12-23\n",
       "104    2019-12-30\n",
       "Name: date, Length: 105, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "strict date parsing failed for 3 value(s) (3 unique): [\"August 2023\", \"July 2023\", \"September 2023\"]\n\nYou might want to try:\n- setting `strict=False`\n- setting `exact=False` (note: this is much slower!)\n- checking whether the format provided ('%d %B %Y') is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39;49mwith_columns(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m'\u001b[39;49m\u001b[39mmonth_year\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mto_date(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mB \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/dataframe/frame.py:7861\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   7710\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwith_columns\u001b[39m(\n\u001b[1;32m   7711\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   7712\u001b[0m     \u001b[39m*\u001b[39mexprs: IntoExpr \u001b[39m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   7713\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   7714\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   7715\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7716\u001b[0m \u001b[39m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   7717\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7856\u001b[0m \n\u001b[1;32m   7857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   7858\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m   7859\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy()\n\u001b[1;32m   7860\u001b[0m         \u001b[39m.\u001b[39;49mwith_columns(\u001b[39m*\u001b[39;49mexprs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnamed_exprs)\n\u001b[0;32m-> 7861\u001b[0m         \u001b[39m.\u001b[39;49mcollect(no_optimization\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   7862\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/utils/deprecation.py:95\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     92\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     93\u001b[0m         old_name, new_name, kwargs, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, version\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seo/lib/python3.11/site-packages/polars/lazyframe/frame.py:1695\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, streaming)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     comm_subplan_elim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1686\u001b[0m     type_coercion,\n\u001b[1;32m   1687\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     streaming,\n\u001b[1;32m   1694\u001b[0m )\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39mcollect())\n",
      "\u001b[0;31mComputeError\u001b[0m: strict date parsing failed for 3 value(s) (3 unique): [\"August 2023\", \"July 2023\", \"September 2023\"]\n\nYou might want to try:\n- setting `strict=False`\n- setting `exact=False` (note: this is much slower!)\n- checking whether the format provided ('%d %B %Y') is correct"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['month_year'], format='%B %Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_year</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>September 2023</td>\n",
       "      <td>100</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>July 2023</td>\n",
       "      <td>200</td>\n",
       "      <td>2023-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August 2023</td>\n",
       "      <td>150</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month_year  value       date\n",
       "0  September 2023    100 2023-09-01\n",
       "1       July 2023    200 2023-07-01\n",
       "2     August 2023    150 2023-08-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 7)\n",
      "┌──────────┬─────────┬────────┬─────────┬────────────┬───────────┬────────────┐\n",
      "│ position ┆ web_ctr ┆ web_ws ┆ web_kws ┆ mobile_ctr ┆ mobile_ws ┆ mobile_kws │\n",
      "│ ---      ┆ ---     ┆ ---    ┆ ---     ┆ ---        ┆ ---       ┆ ---        │\n",
      "│ str      ┆ f64     ┆ str    ┆ str     ┆ f64        ┆ str       ┆ str        │\n",
      "╞══════════╪═════════╪════════╪═════════╪════════════╪═══════════╪════════════╡\n",
      "│ 1        ┆ 32.09   ┆ 79332  ┆ 1339128 ┆ 28.23      ┆ 81628     ┆ 3047924    │\n",
      "│ 2        ┆ 14.86   ┆ 67417  ┆ 842771  ┆ 15.38      ┆ 80586     ┆ 1990388    │\n",
      "│ 3        ┆ 8.77    ┆ 66543  ┆ 821482  ┆ 9.7        ┆ 76322     ┆ 1884927    │\n",
      "│ 4        ┆ 5.75    ┆ 67316  ┆ 783050  ┆ 6.23       ┆ 75430     ┆ 1692433    │\n",
      "│ …        ┆ …       ┆ …      ┆ …       ┆ …          ┆ …         ┆ …          │\n",
      "│ 17       ┆ 0.74    ┆ 49453  ┆ 105248  ┆ 1.33       ┆ 40558     ┆ 79449      │\n",
      "│ 18       ┆ 0.7     ┆ 48820  ┆ 100361  ┆ 1.28       ┆ 38505     ┆ 70429      │\n",
      "│ 19       ┆ 0.62    ┆ 48133  ┆ 95376   ┆ 1.2        ┆ 37602     ┆ 64461      │\n",
      "│ 20       ┆ 0.58    ┆ 47572  ┆ 91276   ┆ 1.18       ┆ 35552     ┆ 58582      │\n",
      "└──────────┴─────────┴────────┴─────────┴────────────┴───────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import requests\n",
    "import io \n",
    "dfs = pl.DataFrame([])  # List to store dataframes for each keyword\n",
    "inputs = {\n",
    "        \"date\":\"2023-08-01\",\n",
    "        \"searches-type\":\"allSearches\",\n",
    "        \"value\":\"exact\",\n",
    "        \n",
    "        \"format\":\"csv\"\n",
    "        }\n",
    "\n",
    "myAPIToken = 'c186250c0f3ba9502c38caa53efc7edb'\n",
    "params = {\n",
    "    \"action\": \"export_ctr\",\n",
    "    \"token\": myAPIToken,  # Get token from environment variable\n",
    "    \"inputs\": '{\"date\":\"2022-08-15\",\"searches-type\":\"allSearches\",\"value\":\"exact\",\"format\":\"json\",\"audience\":\"international\",\"device\":\"allDevices\"}'\n",
    "}\n",
    "\n",
    "\n",
    "url = f\"https://api.awrcloud.com/v2/get.php\"\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Make sure the request was successful before processing\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    #data_io = io.StringIO(data['details'][0])\n",
    "    #df = pl.read_csv(data_io, eol_char='\\\\')\n",
    "\n",
    "    t = pl.DataFrame(data[\"details\"])\n",
    "    print(t)\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to fetch data for keyword: Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'position,web_ctr,web_ws,web_kws,mobile_ctr,mobile_ws,mobile_kws\\\\n1,31.74,61787,1164966,28.31,62533,2536009\\\\n2,15.28,53143,752744,15.85,60966,1629466\\\\n3,9.97,58424,1539132,8.76,52602,722354\\\\n4,6.45,58191,1385795,5.7,53062,681719\\\\n5,3.98,53862,635926,4.42,59466,1245108\\\\n6,2.89,54920,587165,3.14,60707,1120096\\\\n7,2.15,55811,540273,2.3,62251,1022940\\\\n8,1.66,56403,498368,1.73,63597,936815\\\\n9,1.32,63968,838735,1.32,56529,440049\\\\n10,1.05,62598,661435,1.11,54866,349585\\\\n11,0.91,57373,405738,0.96,50875,230147\\\\n12,0.9,49445,238187,0.97,46532,152431\\\\n13,0.99,43211,118246,0.92,42246,156634\\\\n14,0.98,41344,100827,1.02,36639,108815\\\\n15,0.93,39493,88599,1.11,32423,79937\\\\n16,0.85,38679,80752,1.24,29642,62133\\\\n17,0.8,37627,74155,1.37,27289,51392\\\\n18,0.72,36900,69868,1.38,25699,44827\\\\n19,0.64,36574,66470,1.36,24645,41002\\\\n20,0.61,35600,63499,1.33,23531,37730\\\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['details'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "df_brand = pl.DataFrame({\n",
    "    \"keyword\": [\"robe\",\"jup\"],\n",
    "    \"brand_domain\": [\"zalando\",\"zar\"],\n",
    "    \"brand_ranking\": [1,4]\n",
    "})\n",
    "\n",
    "# Create a DataFrame with columns: position and ctr\n",
    "df_ctr = pl.DataFrame({\n",
    "    \"position\": [1,4],\n",
    "    \"ctr\": [4500,5000\n",
    "            ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>position</th><th>ctr</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>4500</td></tr><tr><td>4</td><td>5000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────────┬──────┐\n",
       "│ position ┆ ctr  │\n",
       "│ ---      ┆ ---  │\n",
       "│ i64      ┆ i64  │\n",
       "╞══════════╪══════╡\n",
       "│ 1        ┆ 4500 │\n",
       "│ 4        ┆ 5000 │\n",
       "└──────────┴──────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_brand.join(df_ctr,left_on=\"brand_ranking\", right_on=\"position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>keyword</th><th>brand_domain</th><th>brand_ranking</th><th>ctr</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;robe&quot;</td><td>&quot;zalando&quot;</td><td>1</td><td>4500</td></tr><tr><td>&quot;jup&quot;</td><td>&quot;zar&quot;</td><td>4</td><td>5000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌─────────┬──────────────┬───────────────┬──────┐\n",
       "│ keyword ┆ brand_domain ┆ brand_ranking ┆ ctr  │\n",
       "│ ---     ┆ ---          ┆ ---           ┆ ---  │\n",
       "│ str     ┆ str          ┆ i64           ┆ i64  │\n",
       "╞═════════╪══════════════╪═══════════════╪══════╡\n",
       "│ robe    ┆ zalando      ┆ 1             ┆ 4500 │\n",
       "│ jup     ┆ zar          ┆ 4             ┆ 5000 │\n",
       "└─────────┴──────────────┴───────────────┴──────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m t\u001b[39m.\u001b[39;49mselect(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mbrand_ranking\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mto_list()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": [
    "t.select(pl.col(\"brand_ranking\")).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[\"brand_ranking\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = \"./Book1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_excel(uploaded_file,read_csv_options={\"has_header\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;robe&quot;</td></tr><tr><td>&quot;jupe&quot;</td></tr><tr><td>&quot;pull&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌──────────┐\n",
       "│ column_1 │\n",
       "│ ---      │\n",
       "│ str      │\n",
       "╞══════════╡\n",
       "│ robe     │\n",
       "│ jupe     │\n",
       "│ pull     │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = data['column_1'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robe', 'jupe', 'pull']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test\"\n",
    "tablename = \"table\"\n",
    "table_id = \"{}_{}\".format(path, tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_table'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_input = [\"robe courte\",\"jupe\",\"pull\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 61\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m keywords \u001b[39m=\u001b[39m keywords_input\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "keywords = keywords_input.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_ranking (keywords,DB,your_brand_domain): \n",
    "    \n",
    "    dfs_r = pl.DataFrame([])  # List to store dataframes for each keyword\n",
    "    your_brand_position = None\n",
    "    competitors = pl.DataFrame([])\n",
    "    t = pl.DataFrame([])\n",
    "    b = pl.DataFrame([])\n",
    "    rank = pl.DataFrame([])\n",
    "    API_KEY_SEM = 'e31f38c36540a234e23b614a7ffb4fc4'\n",
    "    for keyword in keywords:\n",
    "        url = f\"https://api.semrush.com/?type=phrase_organic&key={API_KEY_SEM}&phrase={keyword}&export_columns=Kd,Dn,Po,&database={DB}\"\n",
    "        response = requests.get(url)\n",
    "        # Make sure the request was successful before processing\n",
    "        if response.status_code == 200:\n",
    "            df = pl.read_csv(io.StringIO(response.text), separator=';', eol_char='\\n').with_columns(Key=pl.lit(keyword))\n",
    "            dfs_r = dfs_r.vstack(df)\n",
    "\n",
    "            for i in range(len(df)):\n",
    "                domain = df['Domain'][i]\n",
    "                position = df['Position'][i]\n",
    "                Keys = df['Key'][i]\n",
    "                for j in range (len(your_brand_domain)):\n",
    "                    if (domain in your_brand_domain[j]) or (your_brand_domain[j] in domain):\n",
    "                        your_brand_position = position\n",
    "    \n",
    "                        b = b.with_columns(keyword = pl.lit(Keys),brand_domain = pl.lit(your_brand_domain[j]),brand_ranking= pl.lit(your_brand_position))\n",
    "                        rank = rank.vstack(b)\n",
    "    \n",
    "                    else:\n",
    "                        t = t.with_columns(keyword = pl.lit(Keys),brand_domain = pl.lit(domain), brand_ranking= pl.lit(position)).head(10)\n",
    "                        competitors = competitors.vstack(t)            \n",
    "        else:\n",
    "            print(f\"Failed to fetch data for keyword: {keyword}. Status Code: {response.status_code}\")\n",
    "            \n",
    "    if rank.is_empty(): \n",
    "        return rank, rank, competitors.unique(maintain_order=True)\n",
    "    else : \n",
    "        return rank,rank.pivot(values=\"brand_ranking\",index=\"keyword\",columns=\"brand_domain\")   , competitors.unique(maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import polars as pl\n",
    "import io\n",
    "import pandas as pd\n",
    "import streamlit_authenticator as stauth\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import datetime \n",
    "import xlsxwriter\n",
    "import plotly.express as px\n",
    "pl.Config.set_tbl_hide_column_data_types(True)\n",
    "from streamlit_extras.dataframe_explorer import dataframe_explorer\n",
    "from pandas.api.types import (\n",
    "    is_categorical_dtype,\n",
    "    is_datetime64_any_dtype,\n",
    "    is_numeric_dtype,\n",
    "    is_object_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_sem = \"fr\"\n",
    "your_brand_domain_input = [\"carrefour\"]\n",
    "keywords = [\"course\"]\n",
    "rank_,rankings, competition = brand_ranking(keywords,DB_sem,your_brand_domain_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 0)</small><table border=\"1\" class=\"dataframe\"><thead><tr></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 0)\n",
       "┌┐\n",
       "╞╡\n",
       "└┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_location = [\"Italie\",\"France\",\"Allemagne\"]\n",
    "list_location.index(\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searche_type = [\"allSearches\",\"branded\",\"search-intent\",\"long-tail\",\"categories\"]\n",
    "    devices = [\"allDevices\",\"desktop\",\"mobile\",\"tablet\"]\n",
    "    audience = [\"international\",\"us\",\"uk\",\"aus\"]\n",
    "    value = [\"exact\",\"average\"]\n",
    "    st.write(\"\\n\\n\\n\")\n",
    "    end_rank = st.number_input('Insert the desired ranking', min_value = 1, max_value = 20, step = 1)\n",
    "    st.title(\"Advanced Web Ranking\")\n",
    "    col1, col2,col3 = st.columns(3)\n",
    "    with col1:\n",
    "        web_date = st.date_input(\"Choose a month\",value = max_,format=\"YYYY-MM-DD\",max_value =max_,min_value =min_)\n",
    "        web_date = web_date.strftime(\"%Y-%m-%d\")\n",
    "        web_date_final = set_day_to_15(web_date)\n",
    "        #web_date_final = datetime.datetime.strptime(web_date_final, \"%Y-%m-%d\")\n",
    "    with col2:\n",
    "        web_search = st.selectbox(\"Select search type:\", searche_type) \n",
    "    with col3:\n",
    "        web_device = st.selectbox(\"Select search type:\", devices)# Add more countries as needed\n",
    "    col4, col5 = st.columns(2)   \n",
    "    with col4:\n",
    "        web_aud = st.selectbox(\"Select an audience:\", audience)  # Add more countries as needed    \n",
    "    with col5:\n",
    "        web_val = st.selectbox(\"Select value type:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_date = \"2023-09-15\"\n",
    "web_date_final = datetime.datetime.strptime(web_date, \"%Y-%m-%d\")\n",
    "web_search = \"allSearches\"\n",
    "web_val = \"exact\"\n",
    "web_device = \"allDevices\"\n",
    "web_aud = \"international\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.strptime(\"2023-09-15\",\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 2)\n",
      "┌──────────┬─────────┐\n",
      "│ position ┆ web_ctr │\n",
      "╞══════════╪═════════╡\n",
      "│ 1        ┆ 31.3    │\n",
      "│ 2        ┆ 14.94   │\n",
      "│ 3        ┆ 8.65    │\n",
      "│ 4        ┆ 5.73    │\n",
      "│ …        ┆ …       │\n",
      "│ 17       ┆ 0.95    │\n",
      "│ 18       ┆ 0.9     │\n",
      "│ 19       ┆ 0.81    │\n",
      "│ 20       ┆ 0.74    │\n",
      "└──────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import polars as pl \n",
    "\n",
    "try:     \n",
    "    myAPIToken = 'c186250c0f3ba9502c38caa53efc7edb'\n",
    "    params = {\n",
    "        \"action\": \"export_ctr\",\n",
    "        \"token\": myAPIToken,  # Get token from environment variable\n",
    "        \"inputs\": f'{{\"date\":\"{web_date}\", \"searches-type\":\"{web_search}\", \"value\":\"{web_val}\", \"device\":\"{web_device}\", \"audience\":\"{web_aud}\", \"format\":\"json\"}}'\n",
    "    }\n",
    "    \n",
    "    url = f\"https://api.awrcloud.com/v2/get.php\"\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Make sure the request was successful before processing\n",
    "    data = response.json()\n",
    "    web_ranking = pl.DataFrame(data[\"details\"]).with_columns(pl.col(\"position\").cast(pl.Int32).alias(\"position\")).select([\"position\",\"web_ctr\"])\n",
    "    web_ranking\n",
    "    print(web_ranking)\n",
    "except : \n",
    "    print(\"error 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 12\n",
    "max_ = 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mean((web_ranking.filter(pl.col(\"position\")==max_).select(\"web_ctr\").item(),web_ranking.filter(pl.col(\"position\")==max_-1).select(\"web_ctr\").item(),web_ranking.filter(pl.col(\"position\")==max_-2).select(\"web_ctr\").item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Store Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nathzu69</td>\n",
       "      <td>Mise à jour</td>\n",
       "      <td>Une mise à jour qui ne se fait pas 😡 et une ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clc la tec</td>\n",
       "      <td>c aberrant poto</td>\n",
       "      <td>la tec et la sncbitch remettez vous en questio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itisokaye</td>\n",
       "      <td>Not reliable</td>\n",
       "      <td>If you're publishing in your app a certain tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cécé1be</td>\n",
       "      <td>Nulle</td>\n",
       "      <td>100 fois moins pratique et fiable que celles d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rodwood7</td>\n",
       "      <td>Service déplorable</td>\n",
       "      <td>Je me rends ce matin sur la ligne 98 qui ne s’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author               title  \\\n",
       "0    Nathzu69         Mise à jour   \n",
       "1  clc la tec     c aberrant poto   \n",
       "2   itisokaye        Not reliable   \n",
       "3     Cécé1be               Nulle   \n",
       "4    Rodwood7  Service déplorable   \n",
       "\n",
       "                                             content rating  \n",
       "0  Une mise à jour qui ne se fait pas 😡 et une ap...      1  \n",
       "1  la tec et la sncbitch remettez vous en questio...      1  \n",
       "2  If you're publishing in your app a certain tim...      1  \n",
       "3  100 fois moins pratique et fiable que celles d...      1  \n",
       "4  Je me rends ce matin sur la ligne 98 qui ne s’...      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def fetch_app_store_reviews(app_id, country_code='be'):\n",
    "    url = f\"https://itunes.apple.com/{country_code}/rss/customerreviews/id={app_id}/sortBy=mostRecent/xml\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch reviews\")\n",
    "        return\n",
    "    \n",
    "    root = ET.fromstring(response.content)\n",
    "    reviews = []\n",
    "\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        review = {\n",
    "            'author': entry.find('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name').text,\n",
    "            'title': entry.find('{http://www.w3.org/2005/Atom}title').text,\n",
    "            'content': entry.find('{http://www.w3.org/2005/Atom}content').text,\n",
    "            'rating': entry.find('{http://itunes.apple.com/rss}rating').text\n",
    "        }\n",
    "        reviews.append(review)\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# Example usage\n",
    "app_reviews = fetch_app_store_reviews(\"1438618535\")\n",
    "t = pd.DataFrame(data = app_reviews)\n",
    "t.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Store Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-play-scraper\n",
      "  Downloading google_play_scraper-1.2.4-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: google-play-scraper\n",
      "Successfully installed google-play-scraper-1.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-play-scraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_play_scraper import app\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Market\n",
    "\n",
    "from google_play_scraper import Sort, reviews_all\n",
    "\n",
    "\n",
    "us_reviews = reviews_all(\n",
    "    'be.otw.tecmobile',\n",
    "    sleep_milliseconds=0, # defaults to 0\n",
    "    lang='en', # defaults to 'en'\n",
    "    country='be', # defaults to 'us'\n",
    "    sort=Sort.NEWEST, # defaults to Sort.MOST_RELEVANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ee8ed3e1-ff53-4bd6-bafd-234f8b64f35e</td>\n",
       "      <td>Arno van den Heuvel</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>Just doesn't work. Can't register. Doesn't fin...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5.1</td>\n",
       "      <td>2023-11-01 08:45:59</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2eb5e40b-1b55-4834-a07d-63d67b2e540e</td>\n",
       "      <td>Lars Voesterzoons</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>The app doesn't open half the time and when it...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>2023-08-31 16:57:41</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e810518f-3d87-4ad1-8920-8c3601ca5c56</td>\n",
       "      <td>Alireza Bahmanyar</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>100% rubbish. I use bus 48 twice a day to get ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2023-08-18 17:30:04</td>\n",
       "      <td>Hi! We apologize for these issues. Could you p...</td>\n",
       "      <td>2023-08-21 09:31:02</td>\n",
       "      <td>2.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2a67c795-6054-4b6f-ad46-add61bc4884c</td>\n",
       "      <td>B P'ennacchi</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>Validation of tickets is heavily dependent on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2023-07-05 18:15:43</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716811b0-3cfd-4b91-aa24-f726d6212452</td>\n",
       "      <td>Peter S</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>Miserable app. I still can't confirm my accoun...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2023-08-05 10:29:23</td>\n",
       "      <td>Hi! Our deepest apologies on this issue. Have ...</td>\n",
       "      <td>2023-08-10 09:08:42</td>\n",
       "      <td>2.4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId             userName  \\\n",
       "0  ee8ed3e1-ff53-4bd6-bafd-234f8b64f35e  Arno van den Heuvel   \n",
       "1  2eb5e40b-1b55-4834-a07d-63d67b2e540e    Lars Voesterzoons   \n",
       "2  e810518f-3d87-4ad1-8920-8c3601ca5c56    Alireza Bahmanyar   \n",
       "3  2a67c795-6054-4b6f-ad46-add61bc4884c         B P'ennacchi   \n",
       "4  716811b0-3cfd-4b91-aa24-f726d6212452              Peter S   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "1  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "2  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "4  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Just doesn't work. Can't register. Doesn't fin...      1              3   \n",
       "1  The app doesn't open half the time and when it...      2              2   \n",
       "2  100% rubbish. I use bus 48 twice a day to get ...      1              3   \n",
       "3  Validation of tickets is heavily dependent on ...      1              2   \n",
       "4  Miserable app. I still can't confirm my accoun...      1              2   \n",
       "\n",
       "  reviewCreatedVersion                  at  \\\n",
       "0                2.5.1 2023-11-01 08:45:59   \n",
       "1                2.5.0 2023-08-31 16:57:41   \n",
       "2                2.4.1 2023-08-18 17:30:04   \n",
       "3                2.4.1 2023-07-05 18:15:43   \n",
       "4                2.4.1 2023-08-05 10:29:23   \n",
       "\n",
       "                                        replyContent           repliedAt  \\\n",
       "0                                               None                 NaT   \n",
       "1                                               None                 NaT   \n",
       "2  Hi! We apologize for these issues. Could you p... 2023-08-21 09:31:02   \n",
       "3                                               None                 NaT   \n",
       "4  Hi! Our deepest apologies on this issue. Have ... 2023-08-10 09:08:42   \n",
       "\n",
       "  appVersion  \n",
       "0      2.5.1  \n",
       "1      2.5.0  \n",
       "2      2.4.1  \n",
       "3      2.4.1  \n",
       "4      2.4.1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_busu = pd.DataFrame(np.array(us_reviews),columns=['review'])\n",
    "\n",
    "\n",
    "df_busu = df_busu.join(pd.DataFrame(df_busu.pop('review').tolist()))\n",
    "\n",
    "\n",
    "\n",
    "df_busu.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/4d/d3/38b09813a32618acd437906c4d0194119e27139dbcd7486e69d58e375a27/regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m23.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m6.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.3.2 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/warfaoui/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a SentimentIntensityAnalyzer object\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Sample user review\n",
    "user_review = t[\"content\"][0]\n",
    "\n",
    "# Get sentiment scores\n",
    "sentiment_scores = sia.polarity_scores(user_review)\n",
    "\n",
    "print(sentiment_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Une mise à jour qui ne se fait pas 😡 et une application impossible à utiliser que faire ????'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral sentiment\n"
     ]
    }
   ],
   "source": [
    "compound_score = sentiment_scores['compound']\n",
    "if compound_score >= 0.05:\n",
    "    print(\"Positive sentiment\")\n",
    "elif compound_score <= -0.05:\n",
    "    print(\"Negative sentiment\")\n",
    "else:\n",
    "    print(\"Neutral sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/c5/0e/8961075de3aca5435fa6371088d44594cdc0e59b5b935afdaf1af028cf36/tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/91/4f/bded5d0435a72f1bd39f5aaa81077d84fa39526a7c055cc8b8aa44fce681/safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/7.9 MB\u001b[0m \u001b[31m7.7 kB/s\u001b[0m eta \u001b[36m0:16:55\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/http/client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 248, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 161, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 565, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 479, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/warfaoui/anaconda3/envs/seo/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Une mise à jour qui ne se fait pas 😡 et une application impossible à utiliser que faire ????',\n",
       " 'la tec et la sncbitch remettez vous en question jsp c une dinguerie d’être autant mal aimé',\n",
       " \"If you're publishing in your app a certain timetable for your buses, it should reflect reality. If not, at least remove those schedules and not waste the consumer's time.\",\n",
       " '100 fois moins pratique et fiable que celles de la STIB, DE LIJN, RATP, CTS ou SNCB…',\n",
       " 'Je me rends ce matin sur la ligne 98 qui ne s’arrête pas à 8h17 à l’arrêt Tihange - Malles Terres… Ce « service » public est à revoir',\n",
       " 'Bus toujours en retard ou en grève',\n",
       " 'Si vous devez partir à 16h50, c’est pas à 49! C’est qu’une minute ? Ça compte quand même!!! Et ne me dite pas que j’ai pas la même heure que le chauffeur on a tout les deux l’heure satellite!! On s’organise pour essayer d’être la à l’heure mais vous partez plus tôt c’est très énervant !!! (Ligne 51 Namur gare - st Nicolas 9 novembre 2023 à 16h50)',\n",
       " 'je souhaite aller d’un point A a un point B, et le service de BUS m’indique d’utiliser le TRAIN.\\nje sais qu’il y un manque de confiance envers les bus mais vous pouvez juste indiquer votre service au lieu des autres….',\n",
       " 'L’option que propose l’application, pour suivre en temps réel le bus, ne fonctionne pas !!',\n",
       " 'Déconnexions intempestives \\nSuivi des véhicules en temps réels qui fonctionne une fois sur 10\\nRecherche complètement fantaisiste ( je demande arrêt à proximité, me donne un arrêt à 10kms!!!\\nImpossible de suivre les véhicules en retard \\nTrajets marqués comme supprimés mais qui circulent en réalité \\nTrajets marqués comme circulant mais supprimés \\nInformations sur les perturbations difficilement accessibles \\nEt j’en passe ! Je me demande comment on ose mettre une telle application en production !!',\n",
       " 'L’application est bien, elle fonctionne bien mais il manque deux fonctionnalités qui serait franchement appréciable : 1. Pouvoir ajouter notre abonnement à \"Cartes\" 2. Ajouter les notifications \"Activités en direct\" ajoutée avec iOS 16.1, ce qui permettrait d’être plus interactif qu’une bête notification envoyée pendant le trajet. Ces deux fonctionnalités rendrait l’application du TEC parfaite !',\n",
       " 'Ravi de l’application merci',\n",
       " 'Le réseau TEC est toujours aussi mal desservi. Aucune réponse au réclamation pour bus encore et toujours en retard',\n",
       " 'Il n’y a pas de bus de l’Air Pur Seraing à Plainevaux. \\nC’est assez embêtant car nous sommes nombreux à vouloir aller à cet endroit…',\n",
       " '1) Les heures d’arrivée ne sont pas correctes. Ce qui fait qu’on se trouve à attendre dans le froid pour rien. Ça a le temps de faire des grèves mais faire son travail et arriver à l’heure ça par contre…\\nLes bus viennent en avance de 5-6 minutes parfois. Comment s’organiser de cette manière ?\\n\\n2) Déconnecte les comptes au pire moment avant de monter à bord pour refuser le bon identifiant et mot de passe. Comment c’est possible? \\nJe rechange le mot de passe, c’est confirmé, je réessaye et l’application dit faux mot de passe.\\n\\nLe service client li est niquel par contre!',\n",
       " 'Bad app',\n",
       " 'Je tente par tous les moyens de me créer un compte afin de m’acheter un titre de transport 30 minutes avant mon bus (comme je le fais sans souci avec la STIB ou la SNCB) cependant l’application me dit que j’ai déjà un compte existant et qu’un mail me sera envoyé… rien reçu… je tente d’en acheter un directement sur ma carte Mobib, pas disponible avant demain. Je revérifie ma boîte mail, toujours rien. J’arrive à l’arrêt de bus, aucune borne pour acheter un ticket donc j’attends le bus et une fois dedans on me dit qu’il n’y a possibilité de payer que en cash et pas par carte… alors que dans tous les autres transports en commun de Belgique c’est faisable… très étonnée et déçue du fonctionnement de l’achat des titres de transport TEC.',\n",
       " 'L’application ne mentionne ni les retard, ni les avances et elle ne mentionne souvent pas les bus annulés ! Contrairement à Google maps qui lui est beaucoup plus fournie. Par exemple il dit si le bus est en retard ou en avance, il dit si il y a beaucoup de monde ou non. Je ne sais même pas combien de fois j’ai fais confiance à l’application qui m’affiche mon bus à 7h47 et quand j’arrive à 45 on me dit qu’il est passé à 43…',\n",
       " 'Il est dommage que certains bus signalés quelques arrêts avant le mien disparaissent des radars et n’arrivent tout simplement pas…. C’est frustrant….',\n",
       " 'C’est vraiment dérangeant que quand l’application est en maintenance impossible de pouvoir scanner mon ticket. Résultat, je n’ai pas pu rentrée chez moi, l’appli dis être en maintenance jusqu’au 24. Nous sommes le 25 et je suis sensé aller en cours mais je suis coincée car pas de monnaie, pas de quoi me prendre une carte physique et les chauffeurs, non compréhensifs, ne me laisse pas monter à bord malgré la preuve de la présence du bug d’appli et la présence d’un ticket. \\nEnfin évitez de mettre votre appli en maintenance en laissant tout ne pas fonctionner c’est un peu embêtant quand on a pas d’autre moyen de transport.',\n",
       " 'Pas de vue d’ensemble d’un horaire d’une ligne. On cherche un bus par exemple à 10h59, c’est oups erreur survenue, on met 11h59 , on trouve le prochain disponible à 15h26.., pourquoi ne pas avoir tous les horaires par jour ? Pénible cette app !',\n",
       " 'Un Qr code à chaque arrêt physique pour être redirigé vers l’arrêt du bus dans  l’application.\\n\\nPour d’autres idées contactez moi 😌',\n",
       " 'L’app Tec, il faut s’y retrouver c’est pas la plus simple. En plus, le service des pertes ne vous répond même pas. Je pensais que l’époque club Med était finie',\n",
       " 'Le nombre de fois où j’ai pris le métro à Charleroi et que l’app disait que les métro étaient passés alors qu’en réalité il n’y en avait pas eu un seul c’est un peu saoulant\\n\\nCe qui serait bien, ça serait de pourvoir ajouter des titre à même la carte MoBIB, sans passer via le web shop, comme on peut le faire aux bornes on peut déjà scanner les cartes MoBIB via l’application MoBIB afin de savoir ce qu’il nous reste sur la cartes etc mais ça serait bien de pouvoir la recharger ;)',\n",
       " 'Application comparable au service, décevant (mais de temps en temps utile quand ça fonctionne)',\n",
       " 'Application complètement inutile, pas mise a jour donc les arrêts supprimés et déplacés sont toujours proposés. On tape l’itinéraire et il nous fait descendre à un arrêté supprimé depuis 2020!!!! Il y a un petit triangle avec une quinzaine de perturbations, impossible de s’y retrouver correctement',\n",
       " 'On ne sait jamais si le bus est déjà passé ou est annulé… évidemment pas à l’heure comme d’habitude !!!',\n",
       " 'L’application indique trop souvent que des bus sont déjà partis et qu’ils ont quitté l’arrêt alors que ces bus n’existent pas.\\n\\nIl m’arrive trop souvent d’arriver en retard à cause de ces bus fantômes et d’attendre à l’arrêt inutilement !',\n",
       " 'Problèmes fréquents lors de la mise a jours de l’application tant au niveau de l’identification qu’il faut remettre à chaque fois que dans le processus de paiement qui bug. Il serait temps que la tec se ramasse de la concurrence où prennent exemple sur nos homonyme flamand !',\n",
       " 'Quand il passe à la rue duchataux',\n",
       " 'Merci le tec pour cette arnaque j’ai payer un ticket dans le recevoir mais j’ai bien été débilités par contre !',\n",
       " 'L’application fonctionnait très bien jusqu’à hier , elle ne veux plus fonctionner, l’application reste bloquée sur le bus qui roule et puis au bout de 2 min cela affiche le message d’erreur, cela c’est très frustrant car j’utilisais l’application très fréquemment',\n",
       " 'Toujours en retard',\n",
       " 'Je remet le commentaire au cas où vous auriez pas vu j’achète des tickets et rien apparait mais mon argent est quand même prélevé je veux être rembourser',\n",
       " 'Appli a améliorer vrmt',\n",
       " 'Quand je veux mettre mon trajet habituel pour aller à Charleroi il m’affiche une erreur qu’il ne trouve pas mes recherches simple . C’est vraiment très embêtant je viens de l’installer il y’a seulement 3 semaine .\\nLe temps de recherche est très lent je dois attendre plusieur minute pour avoir un résultat pour le trajet à prendre c’est honteux .',\n",
       " 'Gros beug mes ticket n’apparaissent pas toujours mais ça nous prélève de l’argent sur le compte en banque',\n",
       " 'extrêmement déçu par le service de transport en commun TEC et je tiens à partager mon expérience inquiétante avec les autres utilisateurs. Lors d\\'un récent trajet, j\\'ai été confronté à une situation choquante qui démontre l\\'incompétence des chauffeurs de bus de cette compagnie. Le jour de l\\'incident, j\\'ai attendu patiemment à l\\'arrêt de bus, espérant arriver à ma destination à temps. Lorsque le bus est enfin arrivé, je me suis approché de la porte, mais avant même que je puisse monter, le chauffeur a refermé violemment les portes du bus, coincant ma main à l\\'intérieur. J\\'étais stupéfait et j\\'ai immédiatement crié pour attirer son attention, mais il a ignoré mes appels à l\\'aide et a commencé à prendre la route. C\\'était une expérience choquante et traumatisante. J\\'ai eu l\\'impression que ma sécurité et mon bien-être n\\'étaient pas une priorité pour ce chauffeur. Il est impensable qu\\'un professionnel du transport en commun puisse agir de manière aussi irresponsable et dangereuse. Les chauffeurs sont censés veiller à ce que les passagers montent et descendent en toute sécurité, et ils devraient être formés pour gérer de telles situations de manière adéquate. Je suis profondément déçu du manque de professionnalisme dont a fait preuve ce chauffeur, et je suis\\n  préoccupé par le fait qu\\'il puisse y en avoir d\\'autres comme lui au sein de la compagnie TEC. J\\'espère que cette expérience servira de signal d\\'alarme et incitera les responsables à prendre des mesures pour garantir la sécurité et la satisfaction des usagers. En tant qu\\'utilisateur régulier des transports en commun, je m\\'attends à un niveau de service bien supérieur. Les passagers méritent d\\'être traités avec respect et de se sentir en sécurité tout au long de leur trajet. Malheureusement, mon expérience avec le service de transport en commun TEC a été tout le contraire. En conclusion, je déconseille fortement d\\'utiliser le service de transport en commun TEC tant que des mesures concrètes ne seront pas prises pour améliorer la formation des chauffeurs et garantir la sécurité des passagers. Il est de la responsabilité de la compagnie de fournir un service fiable et sécurisé, et jusqu\\'à présent, mes expériences avec TEC ont été tout sauf satisfaisantes.\"',\n",
       " 'Il manque une chose plus que primordiale sur l’app ! Ce sont les horaires des lignes !!!',\n",
       " 'Depuis la mise à jour, on ne voit plus où est le bus en temps réel !! C’est scandaleux, le tec montre une nouvelle fois son incapacité. Je ne parle même pas de tous les bugs. L’ancienne version était pourtant meilleure.',\n",
       " 'Facile et très utile',\n",
       " 'Si les arrêts de l’itinéraire ne sont pas modifiés suivant les perturbations l’app ne sert strictement à rien !',\n",
       " 'Éclater au sol y a aucun bus qui passe en vrai alor que sur l’appli y doivent passer nique le tec',\n",
       " '…',\n",
       " 'L’appli montre bien les horaires, mais pas en temps réel. Il montre pas les arrêts que le bus réellement fait.\\n\\n😓😓',\n",
       " 'Vous avez peur qu’on vous fasse remarquer votre manque d’efficacité ? A l’image du service TEC, l’application est inutilisable.',\n",
       " 'Donner l’info sur les arrêts supprimés et déplacés ? Non hein les gens se débrouillent!\\nLe TEC sponsorise l’industrie automobile.',\n",
       " 'Peut-être grand temps de moderniser un peut l’app et plus facile pour : \\n\\n* les paiements des tickets. \\n* les bus en temps réel, parce que ça fonctionne une fois sur deux.\\n* les déviations sur l’app et non sur votre site internet. \\n* ajouter également dans les paramètres une fonctionnalité (en mode clair ou sombre) comme chez votre confrère De Lijn et La Stib. \\n\\nIl est peut-être grand temps que vous faites des nouveautés sur votre app parce que pour regarder les déviations sur le trajet ça t’ouvre la page internet, alors pourquoi pas tout centraliser sur l’app ?.',\n",
       " 'L’app plante souvent.\\nJe dois à chaque fois me reconnecter.\\nEt l’app ne me reconnaît pas alors que mes login et mot de passe sont enregistrés sur mon iPhone. \\nJe dois donc à chaque fois créer un nouveau compte.\\n A fait des années que ça dure et ils ne travaillent même pas sur le problème.\\nQuant aux navettes permettant de rejoindre Bruxelles à partir du BW, il n’y en a pas assez!',\n",
       " 'First off, thank god there’s finally an app. Secondly, when will we be able to pay by card inside the buses ? Rosa Parks had less trouble paying to get a ride in one of those than I do. Third, WHY THE HELL DO I HAVE TO LOG IN EVERYTIME I WANT TO PURCHASE SOMETHING AND WHO’S IDEA WAS IT TO CHOOSE A NICKNAME INSTEAD OF SOMEONE’S EMAIL TO LOGIN, HELLO IT’S THE TEC APP NOT CALL OF DUTY WHO CARES. I just can’t be asked with you guys anymore.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[\"content\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb Cell 89\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#Y154sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the sentiment-analysis pipeline\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/warfaoui/Library/CloudStorage/OneDrive-EY/Desktop/SEO_APP-1/test.ipynb#Y154sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nlp \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39msentiment-analysis\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment-analysis pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Example user review\n",
    "review = t[\"content\"][0]\n",
    "\n",
    "# Analyze sentiment\n",
    "result = nlp(review)[0]\n",
    "\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Review: I just tried the new cafe downtown, and it was amazing! \\nSentiment: I\\'m a pretty \"bunch of friends\" dude who loves coffee and coffee shops, but I like how it gives me a sense of community.  I\\'ve tried different flavors, but this is'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a pipeline\n",
    "nlp = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Example review\n",
    "review = \"I just tried the new cafe downtown, and it was amazing!\"\n",
    "\n",
    "# Generate sentiment analysis\n",
    "response = nlp(f\"Review: {review} \\nSentiment:\", max_length=60)\n",
    "sentiment = response[0]['generated_text'].split('\\n')[1].strip()\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
